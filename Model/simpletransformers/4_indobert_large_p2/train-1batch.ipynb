{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "cuda_available = torch.cuda.is_available()\n",
    "\n",
    "from simpletransformers.ner import NERModel, NERArgs\n",
    "\n",
    "# from ner_eval import collect_named_entities\n",
    "# from ner_eval import compute_metrics\n",
    "# from ner_eval import compute_precision_recall_wrapper\n",
    "\n",
    "# from sklearn_crfsuite import metric\n",
    "from nervaluate import Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='indobenchmark/indobert-large-p2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df =pd.read_csv(\"..\\..\\..\\Dataset\\\\simpletransformers\\\\train.csv\")\n",
    "eval_df =pd.read_csv(\"..\\..\\..\\Dataset\\\\simpletransformers\\\\val.csv\")\n",
    "test_df =pd.read_csv(\"..\\..\\..\\Dataset\\\\simpletransformers\\\\test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = [\n",
    "    \"O\", \n",
    "    \"B-PER\", \"I-PER\",\n",
    "    \"B-ORG\", \"I-ORG\",\n",
    "    \"B-LOC\", \"I-LOC\",\n",
    "    \"B-PROD\", \"I-PROD\",\n",
    "    \"B-WA\", \"I-WA\",\n",
    "    \"B-EV\", \"I-EV\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a NERModel\n",
    "model_args=NERArgs()\n",
    "# model_args.train_batch_size=64\n",
    "# model_args.overwrite_output_dir=True\n",
    "model_args = {\n",
    "    \"output_dir\": \"outputs/\",\n",
    "    \"cache_dir\": \"cache_dir/\",\n",
    "\n",
    "    \"fp16\": True,\n",
    "    \"fp16_opt_level\": \"O1\",\n",
    "    \"max_seq_length\": 128,\n",
    "    \"train_batch_size\": 8,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"eval_batch_size\": 8,\n",
    "    # \"num_train_epochs\": 1,\n",
    "    \"num_train_epochs\": 5,\n",
    "    \"weight_decay\": 0,\n",
    "    \"learning_rate\": 4e-5,\n",
    "\n",
    "    \"adam_epsilon\": 1e-8,\n",
    "    \"warmup_ratio\": 0.06,\n",
    "    \"warmup_steps\": 0,\n",
    "    \"max_grad_norm\": 1.0,\n",
    "\n",
    "    \"logging_steps\": 50,\n",
    "    \"save_steps\": 2000,\n",
    "\n",
    "    \"overwrite_output_dir\": True,\n",
    "    \"reprocess_input_data\": False,\n",
    "    \"evaluate_during_training\": True,\n",
    "\n",
    "    \"do_lower_case\": False, #True if using uncased models\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = NERModel('bert', \n",
    "#                 'outputs/checkpoint-594-epoch-1',\n",
    "#                 args=model_args,\n",
    "#                 labels=label_list,\n",
    "#                 use_cuda=cuda_available,\n",
    "#                 )\n",
    "# # result, model_outputs, wrong_preds = model.eval_model(eval_df)\n",
    "# # result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1.50k/1.50k [00:00<00:00, 1.53MB/s]\n",
      "Downloading: 100%|██████████| 1.25G/1.25G [01:07<00:00, 19.8MB/s]   \n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at indobenchmark/indobert-large-p2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Downloading: 100%|██████████| 224k/224k [00:00<00:00, 235kB/s]  \n",
      "Downloading: 100%|██████████| 112/112 [00:00<00:00, 112kB/s]\n",
      "Downloading: 100%|██████████| 2.00/2.00 [00:00<00:00, 2.00kB/s]\n"
     ]
    }
   ],
   "source": [
    "model = NERModel('bert',\n",
    "                model_name,\n",
    "                args=model_args,\n",
    "                labels=label_list,\n",
    "                use_cuda=cuda_available,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-11 18:59:02 simpletransformers.ner.ner_model INFO:  Converting to features started.\n",
      "100%|██████████| 10/10 [00:06<00:00,  1.51it/s]\n",
      "Epoch 1 of 5:   0%|          | 0/5 [00:00<?, ?it/s]d:\\ner-idn-tweet\\env\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "Epochs 0/5. Running Loss:    0.3234: 100%|██████████| 594/594 [02:13<00:00,  4.45it/s]\n",
      "2021-12-11 19:01:30 simpletransformers.ner.ner_model INFO:  Converting to features started.\n",
      "100%|██████████| 3/3 [00:03<00:00,  1.23s/it]\n",
      "Running Evaluation: 100%|██████████| 149/149 [00:06<00:00, 24.81it/s]\n",
      "Epochs 1/5. Running Loss:    0.1095: 100%|██████████| 594/594 [02:13<00:00,  4.47it/s]\n",
      "2021-12-11 19:04:12 simpletransformers.ner.ner_model INFO:  Features loaded from cache at cache_dir/cached_dev_bert_128_13_1188\n",
      "Running Evaluation: 100%|██████████| 149/149 [00:05<00:00, 25.57it/s]\n",
      "Epochs 2/5. Running Loss:    0.1139: 100%|██████████| 594/594 [02:10<00:00,  4.55it/s]\n",
      "2021-12-11 19:06:47 simpletransformers.ner.ner_model INFO:  Features loaded from cache at cache_dir/cached_dev_bert_128_13_1188\n",
      "Running Evaluation: 100%|██████████| 149/149 [00:06<00:00, 24.54it/s]\n",
      "Epoch 4 of 5:  60%|██████    | 3/5 [07:44<05:06, 153.18s/it]2021-12-11 19:07:51 simpletransformers.ner.ner_model INFO:  Features loaded from cache at cache_dir/cached_dev_bert_128_13_1188\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Running Evaluation: 100%|██████████| 149/149 [00:06<00:00, 24.54it/s]\n",
      "Epochs 3/5. Running Loss:    0.2100: 100%|██████████| 594/594 [02:34<00:00,  3.83it/s]\n",
      "2021-12-11 19:09:36 simpletransformers.ner.ner_model INFO:  Features loaded from cache at cache_dir/cached_dev_bert_128_13_1188\n",
      "Running Evaluation: 100%|██████████| 149/149 [00:06<00:00, 24.74it/s]\n",
      "Epochs 4/5. Running Loss:    0.0113: 100%|██████████| 594/594 [02:10<00:00,  4.54it/s]\n",
      "2021-12-11 19:12:01 simpletransformers.ner.ner_model INFO:  Features loaded from cache at cache_dir/cached_dev_bert_128_13_1188\n",
      "Running Evaluation: 100%|██████████| 149/149 [00:05<00:00, 26.04it/s]\n",
      "Epoch 5 of 5: 100%|██████████| 5/5 [12:57<00:00, 155.48s/it]\n",
      "2021-12-11 19:12:09 simpletransformers.ner.ner_model INFO:  Training of bert model complete. Saved to outputs/.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2970,\n",
       " defaultdict(list,\n",
       "             {'global_step': [594, 1188, 1782, 2000, 2376, 2970],\n",
       "              'train_loss': [0.32335537672042847,\n",
       "               0.10951774567365646,\n",
       "               0.11391420662403107,\n",
       "               0.08033551275730133,\n",
       "               0.2100054770708084,\n",
       "               0.011290247552096844],\n",
       "              'eval_loss': [0.3291379825505834,\n",
       "               0.30366841206114564,\n",
       "               0.3129414471628882,\n",
       "               0.33186973153844773,\n",
       "               0.3418945088082512,\n",
       "               0.3704475175664329],\n",
       "              'precision': [0.5709169054441261,\n",
       "               0.599594868332208,\n",
       "               0.5414560161779576,\n",
       "               0.5505154639175258,\n",
       "               0.5591453882230328,\n",
       "               0.5492443981240229],\n",
       "              'recall': [0.3521873619089704,\n",
       "               0.3923994697304463,\n",
       "               0.4732655766681396,\n",
       "               0.4719399027839152,\n",
       "               0.47414935925762264,\n",
       "               0.4657534246575342],\n",
       "              'f1_score': [0.4356381525006832,\n",
       "               0.47435897435897434,\n",
       "               0.505069559066258,\n",
       "               0.5082084225553176,\n",
       "               0.5131516021042564,\n",
       "               0.5040650406504065]}))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train_model(train_df,  eval_data=eval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-11 19:12:09 simpletransformers.ner.ner_model INFO:  Converting to features started.\n",
      "100%|██████████| 3/3 [00:05<00:00,  1.87s/it]\n",
      "Running Evaluation: 100%|██████████| 186/186 [00:07<00:00, 24.55it/s]\n",
      "2021-12-11 19:12:23 simpletransformers.ner.ner_model INFO: {'eval_loss': 0.19186292326463367, 'precision': 0.7684670373312152, 'recall': 0.6825396825396826, 'f1_score': 0.7229590883616663}\n"
     ]
    }
   ],
   "source": [
    "result, model_outputs, y_pred = model.eval_model(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.19186292326463367,\n",
       " 'precision': 0.7684670373312152,\n",
       " 'recall': 0.6825396825396826,\n",
       " 'f1_score': 0.7229590883616663}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x_test=test_df.groupby('sentence_id')['words'].apply(list)\n",
    "x_test=list(df_x_test)\n",
    "\n",
    "df_y_test=test_df.groupby('sentence_id')['labels'].apply(list)\n",
    "y_test=list(df_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-11 19:12:23 simpletransformers.ner.ner_model INFO:  Converting to features started.\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.78s/it]\n",
      "Running Prediction: 100%|██████████| 1/1 [00:00<00:00, 30.76it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions, raw_outputs = model.predict(\n",
    "    # [\"@PolsekAlian PolriBerikan inovasi-inovasi Polri yang memudahkan masyarakat, kegiatan pemolisian masyarakat dan seluruh tindakan Kepolisian dalam menghadapi gangguan Kamtibmas, dan lain-lain - Jenderal Polisi Drs. Listyo Sigit Prabowo, https://t.co/f8GZ6VPqPD. - Kapolri #PolriTVRadioPresisi\"],\n",
    "    [\"@ShopeeID Bismillah yok menang ���� SHOPEE @ShopeeID #44ShopeeMamamoo #ShopeexMAMAMOO #AdaMamamoodiShopee\"], \n",
    "    [\"@OPPOIndonesia ✍Butuh memori besar 128GB di OPPO A54 buat simpan file-file tugas kuliah dan testimoni online shop -ku ��Semoga oppo A54 bisa menunjang penghasilan keluargaku �� @OPPOIndonesia @nisa_rkt @Bebheey @kus_ica @Erna19_ @Saftriyuni #OPPOA54 https://t.co/bMYIiRb4QF �� 2.921\"]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'@ShopeeID': 'O'},\n",
       "  {'Bismillah': 'O'},\n",
       "  {'yok': 'O'},\n",
       "  {'menang': 'O'},\n",
       "  {'����': 'O'},\n",
       "  {'SHOPEE': 'B-PROD'},\n",
       "  {'@ShopeeID': 'O'},\n",
       "  {'#44ShopeeMamamoo': 'O'},\n",
       "  {'#ShopeexMAMAMOO': 'O'},\n",
       "  {'#AdaMamamoodiShopee': 'O'}]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You appear to be using a legacy multi-label data representation. Sequence of sequences are no longer supported; use a binary array or sparse matrix instead - the MultiLabelBinarizer transformer can convert to this format.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17304/997650567.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Now we create the model again using the best estimators\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m print(sklearn.metrics.classification_report(\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabel_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdigits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     ))\n",
      "\u001b[1;32md:\\ner-idn-tweet\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[0;32m   2074\u001b[0m     \"\"\"\n\u001b[0;32m   2075\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2076\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2077\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2078\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\ner-idn-tweet\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     83\u001b[0m     \"\"\"\n\u001b[0;32m     84\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\ner-idn-tweet\\env\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36mtype_of_target\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m         ):\n\u001b[1;32m--> 300\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    301\u001b[0m                 \u001b[1;34m\"You appear to be using a legacy multi-label data\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m                 \u001b[1;34m\" representation. Sequence of sequences are no\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: You appear to be using a legacy multi-label data representation. Sequence of sequences are no longer supported; use a binary array or sparse matrix instead - the MultiLabelBinarizer transformer can convert to this format."
     ]
    }
   ],
   "source": [
    "#Now we create the model again using the best estimators\n",
    "\n",
    "print(sklearn.metrics.classification_report(\n",
    "    y_test, y_pred, labels=label_list, digits=3\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluator(y_test, y_pred, tags=['LOC', 'PER', 'ORG', 'PROD', 'WA', 'EV'], loader=\"list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "results, results_per_tag = evaluator.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'correct': 2019,\n",
       " 'incorrect': 0,\n",
       " 'partial': 220,\n",
       " 'missed': 618,\n",
       " 'spurious': 279,\n",
       " 'possible': 2857,\n",
       " 'actual': 2518,\n",
       " 'precision': 0.8455123113582208,\n",
       " 'recall': 0.7451872593629681,\n",
       " 'f1': 0.792186046511628}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['partial']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'correct': 2019,\n",
       " 'incorrect': 220,\n",
       " 'partial': 0,\n",
       " 'missed': 618,\n",
       " 'spurious': 279,\n",
       " 'possible': 2857,\n",
       " 'actual': 2518,\n",
       " 'precision': 0.8018268467037332,\n",
       " 'recall': 0.7066853342667133,\n",
       " 'f1': 0.7512558139534884}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['exact']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./results_1_batch.txt\", \"w\") as f:\n",
    "    str_results = repr(results)\n",
    "    f.write(str_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./results_per_tag_1_batch.txt\", \"w\") as f:\n",
    "    str_results_per_tag = repr(results_per_tag)\n",
    "    f.write(str_results_per_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@Yanua02', '@BatuKepla', '@Karsono12732862', '@Andreas50772732', '@AndreMa32495641', '@victorpangkey', '@andriskhas', '@AbyManyuu', '@lizaariani5', '@Nana_Rosaa', '_', '@dwi2dh25', '@BaswirOb', '@Bang__Mus', '@745L023N6', '@Rijani54531379', '@Dewi52502425', '@Celes_being1074', '@Yatimpi97149270', '@begoeloh', '@FEMYLIA_K', '@FKARIN3', '@PRINCESLAMPIR', '@aewin86', '@Elina_Vay', '@amandagempita', '@CynthiaEllenna', '@dchyntiabella', '@Permata_Dewi06', '@Dewianggra91', '@Dewi37492961', '@Putri_Sulita', '@tasya_aa77', '@bunga_lao', '@Rismaliez85', '@SonyaAmriani', '@gituLok', '@hennyindah1404', '@WiwidNurwidaya1', '@OniMeniq74', '@maita_omerta', '@Ek4_Puspita', '@Mahrus30127858', '@Zoer_Riya', '@Reny_soepomo', '@BersamaSahabat4', '@jokowi', '@KPK_RI', '@PerekonomianRI', '@airlangga_hrt', '@KemenkeuRI', 'Infrastruktur', 'adalah', 'fondasi', 'bagi', 'rumah', 'indah', 'Indonesia', 'yg', 'aka', 'dibangun', 'di', 'era', 'pasca', 'Jokowi', 'Jokowi', 'yg', 'bangun', 'fondasi', 'rumahnya', ',', 'lalu', 'Presiden', 'Selanjutnya', '(', 'mungkin', 'Prabowo', ')', 'yg', 'akan', 'membangun', 'bangunan', 'atas', 'rumahnya', 'Terima', 'kasih', 'Jkw', ',', 'mari', 'kita', 'dukung', 'Jkw', 'membangun', 'fondasi', 'rumah', 'Ind']\n",
      "96\n",
      "y_test        96 ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'B-LOC']\n",
      "y_pred before 21 ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 're' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17304/3471062004.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[1;31m# if '�' in x_test[i][j]:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m             \u001b[0mqmark\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'^�+$'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mqmark\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mqmark\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 're' is not defined"
     ]
    }
   ],
   "source": [
    "import re\n",
    "for i in range(len(y_test)):\n",
    "    if len(y_test[i]) != len(y_pred[i]):\n",
    "        print(x_test[i])\n",
    "        print(len(x_test[i]))\n",
    "        print(\"y_test       \",len(y_test[i]),y_test[i])\n",
    "        print(\"y_pred before\",len(y_pred[i]),y_pred[i])\n",
    "        for j in range(len(x_test[i])):\n",
    "            # if '�' in x_test[i][j]: \n",
    "            qmark=re.match(r'^�+$',x_test[i][j])\n",
    "            if qmark:\n",
    "                print(qmark)\n",
    "                y_pred[i].insert(j,'O')\n",
    "        print(\"y_pred after \",len(y_pred[i]), y_pred[i])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "95f69f4171822e9a0d4258a52ad5b962ce921882fa0fb93c07eb68a8992e9dab"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('env': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
