{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit"
  },
  "interpreter": {
   "hash": "2461f3de9216b0230f3f642cc62d97996878fc3ea0be2eafec764018df867278"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "cuda_available = torch.cuda.is_available()\n",
    "\n",
    "from simpletransformers.ner import NERModel, NERArgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"indobenchmark/indobert-lite-large-p1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.read_csv(\"D:\\Drive\\KULEEAH\\Semester 8\\TA Farihin\\Dataset\\\\bert\\\\train.csv\")\n",
    "eval_df=pd.read_csv(\"D:\\Drive\\KULEEAH\\Semester 8\\TA Farihin\\Dataset\\\\bert\\\\val.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "               sentence_id    words labels\n",
       "0      1382601382042103808    Hidup      O\n",
       "1      1382601382042103808  sesedih      O\n",
       "2      1382601382042103808      dan      O\n",
       "3      1382601382042103808  secaper      O\n",
       "4      1382601382042103808      apa      O\n",
       "...                    ...      ...    ...\n",
       "50005  1383190790147436548      gak      O\n",
       "50006  1383190790147436548      ada      O\n",
       "50007  1383190790147436548    kelas      O\n",
       "50008  1383190790147436548        .      O\n",
       "50009  1383190790147436548   aamiin      O\n",
       "\n",
       "[50010 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentence_id</th>\n      <th>words</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1382601382042103808</td>\n      <td>Hidup</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1382601382042103808</td>\n      <td>sesedih</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1382601382042103808</td>\n      <td>dan</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1382601382042103808</td>\n      <td>secaper</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1382601382042103808</td>\n      <td>apa</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>50005</th>\n      <td>1383190790147436548</td>\n      <td>gak</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>50006</th>\n      <td>1383190790147436548</td>\n      <td>ada</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>50007</th>\n      <td>1383190790147436548</td>\n      <td>kelas</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>50008</th>\n      <td>1383190790147436548</td>\n      <td>.</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>50009</th>\n      <td>1383190790147436548</td>\n      <td>aamiin</td>\n      <td>O</td>\n    </tr>\n  </tbody>\n</table>\n<p>50010 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "train_df=train_df[:50010]\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "               sentence_id          words labels\n",
       "0      1385573262067847169         Nadiem  B-PER\n",
       "1      1385573262067847169        Makarim  I-PER\n",
       "2      1385573262067847169             dg      O\n",
       "3      1385573262067847169       Presiden      O\n",
       "4      1385573262067847169           ke-5      O\n",
       "...                    ...            ...    ...\n",
       "27206  1382913410749190149            aku      O\n",
       "27207  1383795163412058114        ekonomi      O\n",
       "27208  1383795163412058114              ,      O\n",
       "27209  1383795163412058114  infrastruktur      O\n",
       "27210  1383795163412058114              ,      O\n",
       "\n",
       "[27211 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentence_id</th>\n      <th>words</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1385573262067847169</td>\n      <td>Nadiem</td>\n      <td>B-PER</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1385573262067847169</td>\n      <td>Makarim</td>\n      <td>I-PER</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1385573262067847169</td>\n      <td>dg</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1385573262067847169</td>\n      <td>Presiden</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1385573262067847169</td>\n      <td>ke-5</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>27206</th>\n      <td>1382913410749190149</td>\n      <td>aku</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>27207</th>\n      <td>1383795163412058114</td>\n      <td>ekonomi</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>27208</th>\n      <td>1383795163412058114</td>\n      <td>,</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>27209</th>\n      <td>1383795163412058114</td>\n      <td>infrastruktur</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>27210</th>\n      <td>1383795163412058114</td>\n      <td>,</td>\n      <td>O</td>\n    </tr>\n  </tbody>\n</table>\n<p>27211 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = [\n",
    "    \"O\", \n",
    "    \"B-PER\", \"I-PER\",\n",
    "    \"B-ORG\", \"I-ORG\",\n",
    "    \"B-LOC\", \"I-LOC\",\n",
    "    \"B-PROD\", \"I-PROD\",\n",
    "    \"B-WA\", \"I-WA\",\n",
    "    \"B-EV\", \"I-EV\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a NERModel\n",
    "model_args=NERArgs()\n",
    "# model_args.train_batch_size=64\n",
    "# model_args.overwrite_output_dir=True\n",
    "model_args = {\n",
    "    \"output_dir\": \"outputs/\",\n",
    "    \"cache_dir\": \"cache_dir/\",\n",
    "\n",
    "    \"fp16\": True,\n",
    "    \"fp16_opt_level\": \"O1\",\n",
    "    \"max_seq_length\": 128,\n",
    "    \"train_batch_size\": 8,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"eval_batch_size\": 8,\n",
    "    # \"num_train_epochs\": 1,\n",
    "    \"num_train_epochs\": 5,\n",
    "    \"weight_decay\": 0,\n",
    "    # \"learning_rate\": 4e-5,\n",
    "    \"learning_rate\": 0.00006828,\n",
    "\n",
    "    \"adam_epsilon\": 1e-8,\n",
    "    \"warmup_ratio\": 0.06,\n",
    "    \"warmup_steps\": 0,\n",
    "    \"max_grad_norm\": 1.0,\n",
    "\n",
    "    \"logging_steps\": 50,\n",
    "    \"save_steps\": 2000,\n",
    "\n",
    "    \"overwrite_output_dir\": True,\n",
    "    \"reprocess_input_data\": False,\n",
    "    \"evaluate_during_training\": True,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = NERModel('bert', \n",
    "#                 'outputs',\n",
    "#                 args=model_args,\n",
    "#                 labels=label_list,\n",
    "#                 use_cuda=cuda_available,\n",
    "#                 )\n",
    "# result, model_outputs, wrong_preds = model.eval_model(eval_df)\n",
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "layer.1.attention.output.LayerNorm.bias', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.19.output.dense.bias', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.14.output.dense.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.14.output.dense.bias', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.12.output.dense.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.15.output.dense.bias', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.23.output.dense.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.17.attention.self.query.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for BertForTokenClassification:\n\tsize mismatch for embeddings.word_embeddings.weight: copying a param with shape torch.Size([30000, 128]) from checkpoint, the shape in current model is torch.Size([30000, 1024]).\n\tsize mismatch for embeddings.position_embeddings.weight: copying a param with shape torch.Size([512, 128]) from checkpoint, the shape in current model is torch.Size([512, 1024]).\n\tsize mismatch for embeddings.token_type_embeddings.weight: copying a param with shape torch.Size([2, 128]) from checkpoint, the shape in current model is torch.Size([2, 1024]).\n\tsize mismatch for embeddings.LayerNorm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for embeddings.LayerNorm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([1024]).",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-c3e888d60aca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m                 \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                 \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabel_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m                 \u001b[0muse_cuda\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcuda_available\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m                 )\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\simpletransformers\\ner\\ner_model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, model_type, model_name, labels, args, use_cuda, cuda_device, onnx_execution_provider, **kwargs)\u001b[0m\n\u001b[0;32m    299\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquantized_model\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m                 self.model = model_class.from_pretrained(\n\u001b[1;32m--> 301\u001b[1;33m                     \u001b[0mmodel_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    302\u001b[0m                 )\n\u001b[0;32m    303\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\transformers\\modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   1218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m             model, missing_keys, unexpected_keys, error_msgs = cls._load_state_dict_into_model(\n\u001b[1;32m-> 1220\u001b[1;33m                 \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_fast_init\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_fast_init\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1221\u001b[0m             )\n\u001b[0;32m   1222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\transformers\\modeling_utils.py\u001b[0m in \u001b[0;36m_load_state_dict_into_model\u001b[1;34m(cls, model, state_dict, pretrained_model_name_or_path, _fast_init)\u001b[0m\n\u001b[0;32m   1358\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1359\u001b[0m             \u001b[0merror_msg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\\n\\t\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1360\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Error(s) in loading state_dict for {model.__class__.__name__}:\\n\\t{error_msg}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1362\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror_msgs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for BertForTokenClassification:\n\tsize mismatch for embeddings.word_embeddings.weight: copying a param with shape torch.Size([30000, 128]) from checkpoint, the shape in current model is torch.Size([30000, 1024]).\n\tsize mismatch for embeddings.position_embeddings.weight: copying a param with shape torch.Size([512, 128]) from checkpoint, the shape in current model is torch.Size([512, 1024]).\n\tsize mismatch for embeddings.token_type_embeddings.weight: copying a param with shape torch.Size([2, 128]) from checkpoint, the shape in current model is torch.Size([2, 1024]).\n\tsize mismatch for embeddings.LayerNorm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for embeddings.LayerNorm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([1024])."
     ]
    }
   ],
   "source": [
    "model = NERModel('bert', \n",
    "                model_name,\n",
    "                args=model_args,\n",
    "                labels=label_list,\n",
    "                use_cuda=cuda_available,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.train_model(train_df,  eval_data=eval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result, model_outputs, wrong_preds = model.eval_model(eval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'eval_loss': 0.401481420783236,\n",
       " 'precision': 0.46971153846153846,\n",
       " 'recall': 0.40725302209253855,\n",
       " 'f1_score': 0.4362580933244028}"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Running Evaluation: 100%|██████████| 269/269 [00:48<00:00,  5.53it/s]\n",
      "d:\\Drive\\KULEEAH\\Semester 8\\TA Farihin\\env\\lib\\site-packages\\numpy\\core\\_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "You appear to be using a legacy multi-label data representation. Sequence of sequences are no longer supported; use a binary array or sparse matrix instead - the MultiLabelBinarizer transformer can convert to this format.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-028199c2e3a2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'micro'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrong_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meval_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf1_multiclass\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\Drive\\KULEEAH\\Semester 8\\TA Farihin\\env\\lib\\site-packages\\simpletransformers\\ner\\ner_model.py\u001b[0m in \u001b[0;36meval_model\u001b[1;34m(self, eval_data, output_dir, verbose, silent, wandb_log, **kwargs)\u001b[0m\n\u001b[0;32m   1111\u001b[0m             \u001b[0msilent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msilent\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m             \u001b[0mwandb_log\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwandb_log\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1113\u001b[1;33m             \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1114\u001b[0m         )\n\u001b[0;32m   1115\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Drive\\KULEEAH\\Semester 8\\TA Farihin\\env\\lib\\site-packages\\simpletransformers\\ner\\ner_model.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, eval_dataset, output_dir, verbose, silent, wandb_log, **kwargs)\u001b[0m\n\u001b[0;32m   1230\u001b[0m         \u001b[0mextra_metrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1231\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1232\u001b[1;33m             \u001b[0mextra_metrics\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_label_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1234\u001b[0m         result = {\n",
      "\u001b[1;32m<ipython-input-15-028199c2e3a2>\u001b[0m in \u001b[0;36mf1_multiclass\u001b[1;34m(labels, preds)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mf1_multiclass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'micro'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrong_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meval_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf1_multiclass\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Drive\\KULEEAH\\Semester 8\\TA Farihin\\env\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Drive\\KULEEAH\\Semester 8\\TA Farihin\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1045\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m                        \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1047\u001b[1;33m                        zero_division=zero_division)\n\u001b[0m\u001b[0;32m   1048\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1049\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Drive\\KULEEAH\\Semester 8\\TA Farihin\\env\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Drive\\KULEEAH\\Semester 8\\TA Farihin\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1173\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'f-score'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1174\u001b[0m                                                  \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1175\u001b[1;33m                                                  zero_division=zero_division)\n\u001b[0m\u001b[0;32m   1176\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Drive\\KULEEAH\\Semester 8\\TA Farihin\\env\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Drive\\KULEEAH\\Semester 8\\TA Farihin\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1432\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1433\u001b[0m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[1;32m-> 1434\u001b[1;33m                                     pos_label)\n\u001b[0m\u001b[0;32m   1435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1436\u001b[0m     \u001b[1;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Drive\\KULEEAH\\Semester 8\\TA Farihin\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1248\u001b[0m                          str(average_options))\n\u001b[0;32m   1249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1250\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1251\u001b[0m     \u001b[0mpresent_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1252\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maverage\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'binary'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Drive\\KULEEAH\\Semester 8\\TA Farihin\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     80\u001b[0m     \"\"\"\n\u001b[0;32m     81\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Drive\\KULEEAH\\Semester 8\\TA Farihin\\env\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36mtype_of_target\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    261\u001b[0m         if (not hasattr(y[0], '__array__') and isinstance(y[0], Sequence)\n\u001b[0;32m    262\u001b[0m                 and not isinstance(y[0], str)):\n\u001b[1;32m--> 263\u001b[1;33m             raise ValueError('You appear to be using a legacy multi-label data'\n\u001b[0m\u001b[0;32m    264\u001b[0m                              \u001b[1;34m' representation. Sequence of sequences are no'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m                              \u001b[1;34m' longer supported; use a binary array or sparse'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: You appear to be using a legacy multi-label data representation. Sequence of sequences are no longer supported; use a binary array or sparse matrix instead - the MultiLabelBinarizer transformer can convert to this format."
     ]
    }
   ],
   "source": [
    "# model.eval_model(eval_df, acc=sklearn.metrics.accuracy_score)\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "\n",
    "def f1_multiclass(labels, preds):\n",
    "    return f1_score(labels, preds, average='micro')\n",
    "    \n",
    "result, model_outputs, wrong_predictions = model.eval_model(eval_df, f1=f1_multiclass, acc=accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.46s/it]\n",
      "Running Prediction: 100%|██████████| 1/1 [00:00<00:00, 20.84it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions, raw_outputs = model.predict(\n",
    "    [\"@PolsekAlian PolriBerikan inovasi-inovasi Polri yang memudahkan masyarakat, kegiatan pemolisian masyarakat dan seluruh tindakan Kepolisian dalam menghadapi gangguan Kamtibmas, dan lain-lain - Jenderal Polisi Drs. Listyo Sigit Prabowo, https://t.co/f8GZ6VPqPD. - Kapolri #PolriTVRadioPresisi\"]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[{'@PolsekAlian': 'O'},\n",
       "  {'PolriBerikan': 'O'},\n",
       "  {'inovasi-inovasi': 'O'},\n",
       "  {'Polri': 'B-ORG'},\n",
       "  {'yang': 'O'},\n",
       "  {'memudahkan': 'O'},\n",
       "  {'masyarakat,': 'O'},\n",
       "  {'kegiatan': 'O'},\n",
       "  {'pemolisian': 'O'},\n",
       "  {'masyarakat': 'O'},\n",
       "  {'dan': 'O'},\n",
       "  {'seluruh': 'O'},\n",
       "  {'tindakan': 'O'},\n",
       "  {'Kepolisian': 'B-ORG'},\n",
       "  {'dalam': 'O'},\n",
       "  {'menghadapi': 'O'},\n",
       "  {'gangguan': 'O'},\n",
       "  {'Kamtibmas,': 'O'},\n",
       "  {'dan': 'O'},\n",
       "  {'lain-lain': 'O'},\n",
       "  {'-': 'O'},\n",
       "  {'Jenderal': 'O'},\n",
       "  {'Polisi': 'O'},\n",
       "  {'Drs.': 'O'},\n",
       "  {'Listyo': 'O'},\n",
       "  {'Sigit': 'O'},\n",
       "  {'Prabowo,': 'I-PER'},\n",
       "  {'https://t.co/f8GZ6VPqPD.': 'O'},\n",
       "  {'-': 'O'},\n",
       "  {'Kapolri': 'O'},\n",
       "  {'#PolriTVRadioPresisi': 'O'}]]"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "predictions"
   ]
  }
 ]
}